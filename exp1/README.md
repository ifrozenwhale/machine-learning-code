# 说明           

## 文件说明                                                                     

- data目录下为本次实验涉及的两个csv文件

- img目录下为图片存储

- 根目录下为代码

## 依赖环境说明

1. matplotlib
2. numpy


## 二分类

可以使用对数几率回归算法进行分类。对输入的数据集，分为数据x和标签y（数据的归类）。首先经过模型fit训练得到参数$w,b$后，线性回归模型$z=w^Tx+b$带入，求得实值$z$，然后利用单位阶跃函数，转化为0-1值，完成二分类。

单位阶跃函数如下：

 $y=\left\{ \begin{array}{c}                                  0, z<0\\ 1\text{，}z\ge 0\\\end{array} \right. $

## 多分类                                           

多分类的实现使用多个二分类器。

这里使用OVR（一对其余）的模式实现，即对于每个分类标签，训练一个以其为正类，其余为负类的二分类器。N分类，需要训练n个2分类器。在测试时，如果只有一个分类器预测为正类，则对应的类别为最终分类结果，如果有多个分类器为正类，则使用置信度最大的类别标记作为分类结果。

简便起见，可以直接使用置信度最大的类别标记作为分类结果，置信度使用sigmod函数输出的值的大小表示。

 

## 数据的预处理

对于数据集的划分，默认采用7：3或者8:2的比例进行训练集/测试集的划分，这里没有划分验证集。数据集的划分尽可能做到均匀和随机，因此，可以选择从输入的数据中，按照标签y分层抽样，对应于程序中split_dataset函数和split_multi_dataset函数（优化后的，通过循环对多个标签分层取样）。



对于二分类，将标签y转化为0-1，便于计算；对于多分类，通过指定本次训练器的正标签，来将其映射为1，其余标签映射为0。


